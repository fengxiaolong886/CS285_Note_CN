# 术语和notation

![img](https://upload-images.jianshu.io/upload_images/15463866-855be3f859416f12.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这里有一点需要注意，observation和state是不一样的。observation是观察到的世界，他是感知层面的部分信息。但是state表达的是了解整个事物的全貌，完整状态。比如观察到一个豹子在捕猎一头羚羊，如果一个汽车开过去的时候挡住了图片上的豹子，这时候汽车是被观察到的信息，而状态还是本质上的豹子在捕猎羚羊。

下一个状态是由上一个状态和动作决定，和之前的所有状态，动作和observation没有的联系。这就满足了Markov性质。这个也是Sequence Decision Making中的重要假设。所以对于observation并不满足Markov性质。

![img](https://upload-images.jianshu.io/upload_images/15463866-f96be0fda3f0b947.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

------

# 什么是Imitation Learning

我们以自动驾驶学习为例，我们可以使用大量人们开车的数据得到observation与action，然后通过监督学习的方法进行学习训练。

![img](https://upload-images.jianshu.io/upload_images/15463866-3c5de1bfd97599fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

这样的方法并不有效。因为我们在训练中的trajectory与实际运行中的trajectory并不会一直，一旦trajectory中间出现一点点偏差，那么结果就会差异很大。我们很难获得充足的数据支撑起学习到高纬度的所有场景。

![img](https://upload-images.jianshu.io/upload_images/15463866-1987080b18d4fa8b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

但是在NVIDIA的一项关于自动驾驶的研究，Bojarski et al. (2016) 收集了3000英里的数据后效果看起来也不错，他们为收集数据的汽车安装了三个摄像头，以获得更充足的数据。

![img](https://upload-images.jianshu.io/upload_images/15463866-517dd0f9995453a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

NVIDIA的做法在更本质上来看，他们的方案是一个稳定控制器 (stabilizing controller)，对于draft的的情况给出了对于偏差的补偿校正。即便我们单条的轨迹可能偏离很大，但是整体轨迹的分布还是比较稳定的：不关于一个特定的有界的区域偏离太多。

![img](https://upload-images.jianshu.io/upload_images/15463866-c238d8c533afceec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# Dagger

------

这让我们引入了一个简单的算法-DAgger，但是这个算法是有问题的，他需要大量的人工介入标注。但是DAgger可以解决分布"drift"的问题。

![img](https://upload-images.jianshu.io/upload_images/15463866-cbaf432fdf67a9f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 模仿专家进行学习的问题

------

有两个原因使得我们经常不能很好地学习专家行为。

第一个是非Markov行为，意思是专家所做的行为可能不完全依赖于当前所看到的东西，这里有个可考虑的方案是根据历史轨迹来进行训练，使用连续帧的图片输入，使用RNN，LSTM等网络架构

第二个是多峰 (multimodal) 行为。当我们要驾驶无人机躲避一棵树的时候，我们可能会向左绕或者向右绕，但如果将这些决策进行平均的话就变成向前飞然后撞上去了。如果我们采用离散的概率分布，其实问题不大：如果离散成(向左飞，向前飞，向右飞)，那么肯定向左向右有一个很大的概率而向前飞概率很低。而如果我们使用连续的概率分布，或者我们将它离散化得非常细，那么概率分布将会一团糟。如果我们使用高斯分布这样的单峰分布，显然是不合理的。这只是一个比较简单的例子，是这类问题的冰山一角，实际中经常发生。那么我们怎么去解决这类问题呢？

![img](https://upload-images.jianshu.io/upload_images/15463866-53aaac8d8ae3617c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![img](https://upload-images.jianshu.io/upload_images/15463866-179773e00f986639.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

第二种是使用Latent Vaiable models，这类模型可以表达任意概率分布：虽然它本身还是输出一个高斯分布或者一个什么其他的简单分布，甚至可以是一个值。现在我们输入的不仅仅是一个观测图像本身，同样也输入一个噪音进去，譬如给定维数的多元高斯噪音，然后得到输出。这一模型可以学习任何的非线性函数，可以把单峰的噪音变成多峰的输出。这种方法的主要问题是这个模型很难训练。

![img](https://upload-images.jianshu.io/upload_images/15463866-67f5f177007e0620.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![img](https://upload-images.jianshu.io/upload_images/15463866-cf1a0a3a42df949e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![img](https://upload-images.jianshu.io/upload_images/15463866-be053eab30985c11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

总结来说，模仿学习通常有一定局限性（分布不匹配的问题、误差累积问题），但有时候能做得不错，如使用一些稳定控制器，或者从稳定轨迹分布中抽样，抑或是使用DAgger之类的算法增加更多的在线数据，理想化地如使用更好的模型来拟合得更完美。